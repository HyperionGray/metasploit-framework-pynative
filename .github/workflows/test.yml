name: MSF Python Framework Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  COVERAGE_THRESHOLD: 80

jobs:
  # Code Quality Checks
  code-quality:
    runs-on: ubuntu-latest
    name: Code Quality
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run flake8
      run: |
        flake8 lib/ test/ --max-line-length=120 --statistics
        
    - name: Run black
      run: |
        black --check --diff lib/ test/
        
    - name: Run isort
      run: |
        isort --check-only --diff lib/ test/
        
    - name: Run bandit security check
      run: |
        bandit -r lib/ -f json -o bandit-results.json
        
    - name: Run safety check
      run: |
        safety check --json --output safety-results.json
        
    - name: Upload security results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-results
        path: |
          bandit-results.json
          safety-results.json

  # Unit Tests
  unit-tests:
    runs-on: ubuntu-latest
    name: Unit Tests
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run unit tests
      run: |
        python run_tests.py --unit --verbose
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: unit-test-results
        path: test-results/unit-results.xml
        
    - name: Upload coverage reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: unit-coverage
        path: htmlcov/unit/

  # Integration Tests
  integration-tests:
    runs-on: ubuntu-latest
    name: Integration Tests
    services:
      # Mock HTTP service for testing
      httpbin:
        image: kennethreitz/httpbin
        ports:
          - 8080:80
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run integration tests
      run: |
        python run_tests.py --integration --verbose
      env:
        TEST_HTTP_SERVICE: http://localhost:8080
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: integration-test-results
        path: test-results/integration-results.xml

  # Security Tests
  security-tests:
    runs-on: ubuntu-latest
    name: Security Tests
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run security tests
      run: |
        python run_tests.py --security --verbose
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-test-results
        path: test-results/security-results.xml

  # Performance Tests
  performance-tests:
    runs-on: ubuntu-latest
    name: Performance Tests
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run performance tests
      run: |
        python run_tests.py --performance --verbose
        
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: benchmark-results
        path: test-results/benchmark-results.json

  # Module Tests
  module-tests:
    runs-on: ubuntu-latest
    name: Module Tests
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run module tests
      run: |
        python run_tests.py --modules --verbose
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: module-test-results
        path: test-results/module-results.xml

  # Compatibility Tests
  compatibility-tests:
    runs-on: ubuntu-latest
    name: Ruby Compatibility Tests
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: '3.0'
        bundler-cache: true
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Install Ruby dependencies
      run: |
        bundle install
        
    - name: Run compatibility tests
      run: |
        python run_tests.py --compatibility --verbose
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: compatibility-test-results
        path: test-results/compatibility-results.xml

  # Multi-platform Tests
  multi-platform:
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ['3.9', '3.10', '3.11', '3.12']
    runs-on: ${{ matrix.os }}
    name: Test Python ${{ matrix.python-version }} on ${{ matrix.os }}
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-${{ matrix.python-version }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run core tests
      run: |
        python run_tests.py --unit --skip-slow
        
    - name: Upload test results
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
        path: test-results/

  # Coverage Report
  coverage:
    runs-on: ubuntu-latest
    name: Coverage Report
    needs: [unit-tests, integration-tests, security-tests, module-tests]
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run all tests with coverage
      run: |
        python run_tests.py --verbose
        
    - name: Check coverage threshold
      run: |
        python -m coverage report --fail-under=${{ env.COVERAGE_THRESHOLD }}
        
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        
    - name: Upload coverage reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: coverage-report
        path: |
          htmlcov/
          coverage.xml

  # Test Summary
  test-summary:
    runs-on: ubuntu-latest
    name: Test Summary
    needs: [code-quality, unit-tests, integration-tests, security-tests, performance-tests, module-tests, compatibility-tests, coverage]
    if: always()
    steps:
    - name: Download all artifacts
      uses: actions/download-artifact@v3
      
    - name: Generate test summary
      run: |
        echo "# Test Results Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "## Test Status" >> $GITHUB_STEP_SUMMARY
        echo "- Code Quality: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Unit Tests: ${{ needs.unit-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Integration Tests: ${{ needs.integration-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Security Tests: ${{ needs.security-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Performance Tests: ${{ needs.performance-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Module Tests: ${{ needs.module-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Compatibility Tests: ${{ needs.compatibility-tests.result }}" >> $GITHUB_STEP_SUMMARY
        echo "- Coverage: ${{ needs.coverage.result }}" >> $GITHUB_STEP_SUMMARY
        
    - name: Check overall status
      run: |
        if [[ "${{ needs.code-quality.result }}" == "success" && 
              "${{ needs.unit-tests.result }}" == "success" && 
              "${{ needs.integration-tests.result }}" == "success" && 
              "${{ needs.security-tests.result }}" == "success" && 
              "${{ needs.module-tests.result }}" == "success" && 
              "${{ needs.coverage.result }}" == "success" ]]; then
          echo "✅ All critical tests passed!"
          exit 0
        else
          echo "❌ Some tests failed!"
          exit 1
        fi